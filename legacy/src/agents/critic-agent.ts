import { z } from 'zod';
import * as fs from 'fs/promises';
import * as path from 'path';
import { SceneGraph, SceneGraphSchema } from '../schemas/index.js';
import { ConfigurationManager } from '../lib/config-manager.js';
import { llmProviderManager, LLMRequest, LLMResponse } from '../lib/llm-provider.js';
import { DualBudgetManager, CostEstimate } from '../lib/dual-budget-manager.js';
import chalk from 'chalk';

// Critic Report Schema
const CriticReportSchema = z.object({
  overallScore: z.number().min(0).max(100),
  qualityAssessment: z.object({
    visualQuality: z.number().min(0).max(100),
    narrativeFlow: z.number().min(0).max(100),
    technicalExecution: z.number().min(0).max(100),
    emotionalImpact: z.number().min(0).max(100)
  }),
  issues: z.array(z.object({
    severity: z.enum(['low', 'medium', 'high', 'critical']),
    category: z.enum(['visual', 'narrative', 'technical', 'performance']),
    description: z.string(),
    suggestion: z.string().optional()
  })),
  strengths: z.array(z.string()),
  recommendations: z.array(z.string()),
  metadata: z.object({
    reviewDate: z.string().datetime(),
    reviewer: z.string(),
    version: z.string()
  })
});

/**
 * Critic/QA Agent: å“è³ªè©•ä¾¡ãƒ»ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æ‹…å½“
 */
export class CriticAgent {
  name = 'critic';
  inputSchema = SceneGraphSchema;
  outputSchema = CriticReportSchema;

  private budgetManager: DualBudgetManager;
  private configManager: ConfigurationManager;
  private systemPrompt: string | null = null;

  constructor(budgetManager?: DualBudgetManager) {
    this.budgetManager = budgetManager || new DualBudgetManager();
    this.configManager = ConfigurationManager.getInstance();
  }

  private async loadSystemPrompt(): Promise<string> {
    if (this.systemPrompt) return this.systemPrompt;

    try {
      const promptPath = path.join(process.cwd(), 'prompts', 'critic', 'v1_system.txt');
      this.systemPrompt = await fs.readFile(promptPath, 'utf8');
      return this.systemPrompt;
    } catch (error) {
      // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®æœ€å°é™ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
      this.systemPrompt = `
ã‚ãªãŸã¯çµŒé¨“è±Šå¯Œãªæ˜ åƒå“è³ªç®¡ç†æ‹…å½“è€…ã§ã™ã€‚
SceneGraphã‚’è©³ç´°ã«åˆ†æã—ã€åŒ…æ‹¬çš„ãªå“è³ªè©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

è©•ä¾¡åŸºæº–ï¼š
1. è¦–è¦šçš„å“è³ª (Visual Quality): æ˜ åƒã®ç¾ã—ã•ã€æ§‹å›³ã€è‰²å½©
2. ãƒŠãƒ©ãƒ†ã‚£ãƒ–ãƒ•ãƒ­ãƒ¼ (Narrative Flow): ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã®æµã‚Œã€æ„Ÿæƒ…ã®èµ·ä¼
3. æŠ€è¡“çš„å®Ÿè¡Œ (Technical Execution): æŠ€è¡“çš„ãªå®Œæˆåº¦ã€ã‚¨ãƒ•ã‚§ã‚¯ãƒˆã®é©åˆ‡æ€§
4. æ„Ÿæƒ…çš„ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ (Emotional Impact): è¦–è´è€…ã¸ã®æ„Ÿæƒ…çš„ãªå½±éŸ¿åŠ›

å„é …ç›®ã‚’0-100ã®ã‚¹ã‚³ã‚¢ã§è©•ä¾¡ã—ã€å…·ä½“çš„ãªæ”¹å–„ææ¡ˆã‚’å«ã‚ã¦ãã ã•ã„ã€‚

**é‡è¦**: reviewDateã¯å¿…ãšISO 8601ã®å®Œå…¨ãªæ—¥æ™‚å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
ä¾‹: "2023-10-01T12:34:56.789Z" ã¾ãŸã¯ "2023-10-01T12:34:56+09:00"
      `.trim();
      return this.systemPrompt;
    }
  }

  async run(sceneGraph: SceneGraph): Promise<z.infer<typeof CriticReportSchema>> {
    console.log(chalk.blue('ğŸ¬ Critic Agent: å“è³ªè©•ä¾¡ãƒ»ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆä¸­...'));

    const config = await this.configManager.getAgentConfig('critic');
    
    const systemPrompt = await this.loadSystemPrompt();

    const userInput = `ä»¥ä¸‹ã®SceneGraphã‚’è©³ç´°ã«åˆ†æã—ã€å“è³ªè©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ï¼š

${JSON.stringify(sceneGraph, null, 2)}

ä»¥ä¸‹ã®å½¢å¼ã§JSONãƒ¬ãƒãƒ¼ãƒˆã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š
- ç·åˆã‚¹ã‚³ã‚¢ (0-100)
- å„è©•ä¾¡é …ç›®ã®ã‚¹ã‚³ã‚¢ (0-100)
- ç™ºè¦‹ã•ã‚ŒãŸå•é¡Œç‚¹ï¼ˆé‡è¦åº¦åˆ¥ï¼‰
- å¼·ã¿
- æ”¹å–„ææ¡ˆ

**é‡è¦**: reviewDateã¯å¿…ãšISO 8601ã®å®Œå…¨ãªæ—¥æ™‚å½¢å¼ï¼ˆä¾‹: "2023-10-01T12:34:56.789Z"ï¼‰ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚`;

    const request: LLMRequest = {
      model: config.provider?.replace('openai:', '') || 'gpt-4o-mini',
      systemPrompt,
      userInput,
      temperature: config.temperature || 0.2,
      maxTokens: config.maxTokens || 6144
    };

    // äºˆç®—ãƒã‚§ãƒƒã‚¯
    const estimatedTokens = Math.ceil((systemPrompt.length + userInput.length) / 3);
    const estimatedCost = estimatedTokens * 0.00015 / 1000;
    
    const costEstimate: CostEstimate = {
      tokens: estimatedTokens,
      estimatedCost: estimatedCost,
      estimatedWallTime: 30 // æ¨å®š30ç§’
    };
    
    const canProceed = await this.budgetManager.checkBudgetLimit(costEstimate);
    if (!canProceed) {
      throw new Error('äºˆç®—åˆ¶é™ã«ã‚ˆã‚Šå“è³ªè©•ä¾¡ã‚’ä¸­æ–­ã—ã¾ã—ãŸ');
    }

    try {
      const provider = llmProviderManager.getProviderForModel(request.model);
      const response = await provider.generateJSON(request, CriticReportSchema);

      await this.budgetManager.addUsage({
        tokens: response.tokensUsed,
        cost: response.costUSD,
        wallTime: response.duration / 1000
      });

      console.log(chalk.green('âœ… å“è³ªè©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†'));
      console.log(chalk.gray(`Tokenä½¿ç”¨é‡: ${response.tokensUsed}, ã‚³ã‚¹ãƒˆ: $${response.costUSD.toFixed(4)}`));
      console.log(chalk.yellow(`ğŸ“Š ç·åˆã‚¹ã‚³ã‚¢: ${response.data.overallScore}/100`));

      return response.data;
    } catch (error) {
      console.error(chalk.red('âŒ å“è³ªè©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã«å¤±æ•—:'), error);
      throw error;
    }
  }
} 