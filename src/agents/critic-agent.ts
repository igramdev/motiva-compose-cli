import { z } from 'zod';
import { BaseAgent } from '../lib/agent-orchestrator.js';
import { BudgetManager } from '../lib/budget.js';
import { SceneGraph, SceneGraphSchema } from '../schemas/index.js';
import { ConfigurationManager, AgentConfig } from '../lib/config-manager.js';
import { OpenAIWrapper, LLMRequest } from '../lib/openai.js';
import chalk from 'chalk';

// Critic Report Schema
const CriticReportSchema = z.object({
  overallScore: z.number().min(0).max(100),
  qualityAssessment: z.object({
    visualQuality: z.number().min(0).max(100),
    narrativeFlow: z.number().min(0).max(100),
    technicalExecution: z.number().min(0).max(100),
    emotionalImpact: z.number().min(0).max(100)
  }),
  issues: z.array(z.object({
    severity: z.enum(['low', 'medium', 'high', 'critical']),
    category: z.enum(['visual', 'narrative', 'technical', 'performance']),
    description: z.string(),
    suggestion: z.string().optional()
  })),
  strengths: z.array(z.string()),
  recommendations: z.array(z.string()),
  metadata: z.object({
    reviewDate: z.string().datetime(),
    reviewer: z.string(),
    version: z.string()
  })
});

/**
 * Critic/QA Agent: å“è³ªè©•ä¾¡ãƒ»ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’æ‹…å½“
 */
export class CriticAgent extends BaseAgent<SceneGraph, z.infer<typeof CriticReportSchema>> {
  name = 'critic';
  inputSchema = SceneGraphSchema;
  outputSchema = CriticReportSchema;

  private openai: OpenAIWrapper;
  private budgetManager: BudgetManager;
  private configManager: ConfigurationManager;

  constructor(budgetManager: BudgetManager, apiKey?: string) {
    super();
    this.openai = new OpenAIWrapper(apiKey);
    this.budgetManager = budgetManager;
    this.configManager = ConfigurationManager.getInstance();
  }

  async run(sceneGraph: SceneGraph): Promise<z.infer<typeof CriticReportSchema>> {
    console.log(chalk.blue('ğŸ¬ Critic Agent: å“è³ªè©•ä¾¡ãƒ»ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ç”Ÿæˆä¸­...'));

    const config = await this.configManager.getAgentConfig('critic');
    
    const systemPrompt = `ã‚ãªãŸã¯çµŒé¨“è±Šå¯Œãªæ˜ åƒå“è³ªç®¡ç†æ‹…å½“è€…ã§ã™ã€‚
SceneGraphã‚’è©³ç´°ã«åˆ†æã—ã€åŒ…æ‹¬çš„ãªå“è³ªè©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

è©•ä¾¡åŸºæº–ï¼š
1. è¦–è¦šçš„å“è³ª (Visual Quality): æ˜ åƒã®ç¾ã—ã•ã€æ§‹å›³ã€è‰²å½©
2. ãƒŠãƒ©ãƒ†ã‚£ãƒ–ãƒ•ãƒ­ãƒ¼ (Narrative Flow): ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã®æµã‚Œã€æ„Ÿæƒ…ã®èµ·ä¼
3. æŠ€è¡“çš„å®Ÿè¡Œ (Technical Execution): æŠ€è¡“çš„ãªå®Œæˆåº¦ã€ã‚¨ãƒ•ã‚§ã‚¯ãƒˆã®é©åˆ‡æ€§
4. æ„Ÿæƒ…çš„ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ (Emotional Impact): è¦–è´è€…ã¸ã®æ„Ÿæƒ…çš„ãªå½±éŸ¿åŠ›

å„é …ç›®ã‚’0-100ã®ã‚¹ã‚³ã‚¢ã§è©•ä¾¡ã—ã€å…·ä½“çš„ãªæ”¹å–„ææ¡ˆã‚’å«ã‚ã¦ãã ã•ã„ã€‚

**é‡è¦**: reviewDateã¯å¿…ãšISO 8601ã®å®Œå…¨ãªæ—¥æ™‚å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
ä¾‹: "2023-10-01T12:34:56.789Z" ã¾ãŸã¯ "2023-10-01T12:34:56+09:00"`;

    const userInput = `ä»¥ä¸‹ã®SceneGraphã‚’è©³ç´°ã«åˆ†æã—ã€å“è³ªè©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ï¼š

${JSON.stringify(sceneGraph, null, 2)}

ä»¥ä¸‹ã®å½¢å¼ã§JSONãƒ¬ãƒãƒ¼ãƒˆã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š
- ç·åˆã‚¹ã‚³ã‚¢ (0-100)
- å„è©•ä¾¡é …ç›®ã®ã‚¹ã‚³ã‚¢ (0-100)
- ç™ºè¦‹ã•ã‚ŒãŸå•é¡Œç‚¹ï¼ˆé‡è¦åº¦åˆ¥ï¼‰
- å¼·ã¿
- æ”¹å–„ææ¡ˆ

**é‡è¦**: reviewDateã¯å¿…ãšISO 8601ã®å®Œå…¨ãªæ—¥æ™‚å½¢å¼ï¼ˆä¾‹: "2023-10-01T12:34:56.789Z"ï¼‰ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚`;

    const request: LLMRequest = {
      model: config.provider?.replace('openai:', '') || 'gpt-4o-mini',
      systemPrompt,
      userInput,
      temperature: config.temperature || 0.2,
      maxTokens: config.maxTokens || 6144
    };

    // äºˆç®—ãƒã‚§ãƒƒã‚¯
    const estimatedTokens = Math.ceil((systemPrompt.length + userInput.length) / 3);
    const estimatedCost = estimatedTokens * 0.00015 / 1000;
    
    const canProceed = await this.budgetManager.checkBudgetLimit(estimatedTokens, estimatedCost);
    if (!canProceed) {
      throw new Error('äºˆç®—åˆ¶é™ã«ã‚ˆã‚Šå“è³ªè©•ä¾¡ã‚’ä¸­æ–­ã—ã¾ã—ãŸ');
    }

    try {
      const response = await this.openai.generateJSON(
        request,
        CriticReportSchema,
        'critic_report_schema'
      );

      await this.budgetManager.addUsage(response.tokensUsed, response.costUSD);

      console.log(chalk.green('âœ… å“è³ªè©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†'));
      console.log(chalk.gray(`Tokenä½¿ç”¨é‡: ${response.tokensUsed}, ã‚³ã‚¹ãƒˆ: $${response.costUSD.toFixed(4)}`));
      console.log(chalk.yellow(`ğŸ“Š ç·åˆã‚¹ã‚³ã‚¢: ${response.data.overallScore}/100`));

      return response.data;
    } catch (error) {
      console.error(chalk.red('âŒ å“è³ªè©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã«å¤±æ•—:'), error);
      throw error;
    }
  }
} 